# AUTOGENERATED! DO NOT EDIT! File to edit: ../02_asf_static.ipynb.

# %% auto 0
__all__ = ['SearchOpera']

# %% ../02_asf_static.ipynb 3
import logging
import os
import re
import tempfile

import asf_search
import ee
from fastcore.basics import patch
import gcsfs
from IPython.display import JSON
import pandas as pd

from sar_asf_to_gee.core import (
    FORMAT_GEE_DATETIME_STRING,
    create_gee_image_collection
)

# %% ../02_asf_static.ipynb 7
class SearchOpera():   

    LOCAL_PROPNAME = 'local_paths'
    GCS_PATH_PROPNAME = 'gcs_path'
    GEE_ASSET_PROPNAME = 'gee_asset'
    
    def __init__(
        self,
        search_opts,
        gcs_bucket,  # GCS bucket
        gee_gcp_project, # GCP project used by Earth Engine
        gee_image_collection=None,  # Name of the Earth Engine ImageCollection (optional)
        local_storage=None,
    ):
        self.search_opts = search_opts
        self.gcs_bucket = gcs_bucket
        self.gee_gcp_project = gee_gcp_project
        self.gee_image_collection = gee_image_collection
        if local_storage:
            self.tempdir = None
            self.local_storage = local_storage
        else:
            self.tempdir = tempfile.TemporaryDirectory() 
            self.local_storage = self.tempdir.name
            logging.debug(f'created temporary directory: {self.tempdir.name}')
        self._search_results=None
        # self._extracted={}
        # self._gcs_path={}

# %% ../02_asf_static.ipynb 10
@patch
def search_count(
    self:SearchOpera,
):
    "Returns a count of records (w/ duplicates)"
    return asf_search.search_count(**self.search_opts)

# %% ../02_asf_static.ipynb 13
@patch
def search(
    self:SearchOpera,
):
    if not self._search_results:
        self._search_results = asf_search.search(**self.search_opts)
    return self._search_results

# %% ../02_asf_static.ipynb 16
@patch
def as_dataframe(
    self:SearchOpera,
):
    "Returns results as a pandas dataframe (w/o duplicates)"
    df = pd.DataFrame.from_records([r.properties for r in self.search()])
    # For datasets that have been processed more than once, retain the last result.
    df = (df.sort_values(by=['processingDate'])
            .drop_duplicates(subset=['groupID',
                                     'beamMode',
                                     'processingLevel',
                                     'startTime',
                                     'stopTime'], keep='last')
    )
    return df

# %% ../02_asf_static.ipynb 18
@patch
def scene_list(
    self:SearchOpera,
):
    return self.as_dataframe()['sceneName'].to_list()

# %% ../02_asf_static.ipynb 22
@patch
def to_local(
    self:SearchOpera,
):
    "Transfer static ASF results to local system, unzip, and update the job dictionary."    
    logging.info(f'Starting asf_static.to_local()')

    for r in self.search():
        logging.info(f'  Processing {r.properties["fileID"]}')
        r.properties['url_set'] = get_urls(r)
        r.properties[self.LOCAL_PROPNAME] = {}
        for url_key, url_value in r.properties['url_set'].items():
            filename = f'{r.properties["fileID"]}_{url_key}.tif'
            asf_search.download_url(
                url=url_value,
                path=self.local_storage,
                filename=filename
            )
            r.properties[self.LOCAL_PROPNAME][url_key] = os.path.join(self.local_storage, filename)
        # display(JSON(r.properties))
    logging.info(f'Finished asf_static.to_local()')

# %% ../02_asf_static.ipynb 27
@patch
def to_gcs(
    self:SearchOpera,
):
    logging.info('Starting to_gcs()')

    fs = gcsfs.GCSFileSystem(token='google_default')

    if not fs.exists(self.gcs_bucket):
        print('Bucket does not exist!!!')
        fs.mkdir(self.gcs_bucket)

    for r in self.search():
        logging.info(f'  Transferring {r.properties["fileID"]}')
        r.properties[self.GCS_PATH_PROPNAME] = {}
        
        for key, local_filepath in r.properties[self.LOCAL_PROPNAME].items():
            path_split = os.path.split(local_filepath)
            filename = path_split[-1]
            gcs_path = f'{self.gcs_bucket}/{filename}'
            
            if fs.exists(gcs_path):
                logging.info(f'  GCS file already exists:\n    {gcs_path}')
            else:
                logging.info(f'  Starting to transfer file to GCS:\n    {gcs_path}')
                # Transfer the local file to GCS.
                print('filename', filename)
                print('gcs_path', gcs_path)
                fs.put_file(
                    lpath=filepath,
                    rpath=gcs_path
                )    
                logging.info(f'  Transferred file to GCS: {gcs_path}')
            r.properties[self.GCS_PATH_PROPNAME][key] = gcs_path

# %% ../02_asf_static.ipynb 32
@patch
def create_gee_asset(
    self:SearchOpera,
):
    "Create an Earth Engine asset."
    logging.info(f'Starting create_gee_asset()')
    
    ee.Initialize(project=self.gee_gcp_project)
    
    create_gee_image_collection(self.gee_gcp_project, self.gee_image_collection)

    for r in self.search():
        logging.info(f'  Creating GEE assets for {r.properties["fileID"]}')
        r.properties[self.GEE_ASSET_PROPNAME] = {}

        display(JSON({'r.meta': r.meta, 'r.properties': r.properties}))
        start_time = r.properties['startTime']
        end_time = r.properties['stopTime']
        description = (f"{r.properties['platform']}"
                       f" - {r.properties['processingLevel']}"
                       f" - {r.properties['beamModeType']}")
        # id = f"{self.job_dict['job_id']}"
        id = r.properties["fileID"]
        
        for band, gcs_path in r.properties[self.GCS_PATH_PROPNAME].items():
            print('band', band)
            print('gcs_path', gcs_path)

            request = {
                'type': 'IMAGE',
                'bands': {  # TODO: Update this once multi-band COG assets are supported
                    'id': band
                },
                'gcs_location': {
                    'uris': [f'gs://{gcs_path}']
                },
                'properties': {
                    'source':  r.properties['url'],
                    'band': band  # TODO: Remove this once multi-band COG assets are supported
                },
                'startTime': start_time,  #.strftime(FORMAT_GEE_DATETIME_STRING),
                'endTime': end_time,  #.strftime(FORMAT_GEE_DATETIME_STRING),
                'description': description
            }

            path_parts = [
                'projects',
                self.gee_gcp_project,
                'assets',
                self.gee_image_collection,
                # TODO: Remove the band suffix once multi-band COG assets are supported
                f'{id}_{band}'.replace(".", "_") 
            ]
            assetname = os.path.join(*[x for x in path_parts if x is not None])


            logging.debug(f'request = {request}')
            logging.debug(f'assetname = {assetname}')
            try:
                ee.data.createAsset(
                    value=request,
                    path=assetname
                )  
                logging.info(f'Finished creating a GEE asset:\n    {assetname}.')
            except ee.EEException as e:
                print(f'e = {e}')
                if "does not exist or doesn't allow this operation" in str(e):
                    raise(e)
                else:
                    raise(e)  # TODO: Add logic to parse the EEException message.
                    logging.info('GEE asset already exists. Skipping.')
